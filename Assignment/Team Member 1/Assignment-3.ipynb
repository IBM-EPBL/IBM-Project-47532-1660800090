{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5YOizw-dT9q"
      },
      "source": [
        "# Importing Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiy1CpnidQ9J",
        "outputId": "0424a3ed-496b-42e1-b9f3-9000f9997a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ROB4BNR_QL"
      },
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXIBx4voSD_B"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSgOZPtLSX9p"
      },
      "outputs": [],
      "source": [
        "train_d=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True)\n",
        "test_d=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qld6q72-SszV",
        "outputId": "42b40938-fb6c-4aa4-dbb9-d05f49357bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "vtrain = train_d.flow_from_directory('/content/drive/MyDrive/flowers/Testing',target_size=(76,76),class_mode='categorical',batch_size=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRGjcgGdT5Q7",
        "outputId": "2c582bf4-1287-4924-f813-284ddce0bacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "vtest = test_d.flow_from_directory('/content/drive/MyDrive/flowers/Training',target_size=(76,76),class_mode='categorical',batch_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh5LMq-uYVR7"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnIn5ph6Ybhq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_0UncKPc1yn"
      },
      "source": [
        "## Add Layers (Convolution, MaxPooling, Flatten, Dense-(Hidden Layers), Output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjIEUYwIZBB-"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(76,76,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500,activation='relu'))\n",
        "model.add(Dense(250,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGGrMjrUdMUk"
      },
      "source": [
        "## Compile The Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdxpLb7ba8zH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nujZ7QM5dPoZ"
      },
      "source": [
        "## Fit The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8YYDH4JNHUd",
        "outputId": "5942b0b9-692a-4e32-c47e-38a5934982ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "22/22 [==============================] - 96s 4s/step - loss: 1.2093 - accuracy: 0.5038 - val_loss: 1.1528 - val_accuracy: 0.5511\n",
            "Epoch 2/15\n",
            "22/22 [==============================] - 69s 3s/step - loss: 1.0804 - accuracy: 0.5810 - val_loss: 1.0132 - val_accuracy: 0.6115\n",
            "Epoch 3/15\n",
            "22/22 [==============================] - 69s 3s/step - loss: 1.0100 - accuracy: 0.6085 - val_loss: 1.0456 - val_accuracy: 0.6139\n",
            "Epoch 4/15\n",
            "22/22 [==============================] - 69s 3s/step - loss: 0.9307 - accuracy: 0.6467 - val_loss: 0.9421 - val_accuracy: 0.6442\n",
            "Epoch 5/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.8715 - accuracy: 0.6623 - val_loss: 0.9009 - val_accuracy: 0.6674\n",
            "Epoch 6/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.8210 - accuracy: 0.6965 - val_loss: 0.9099 - val_accuracy: 0.6801\n",
            "Epoch 7/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.7659 - accuracy: 0.7169 - val_loss: 0.7732 - val_accuracy: 0.7239\n",
            "Epoch 8/15\n",
            "22/22 [==============================] - 72s 3s/step - loss: 0.7307 - accuracy: 0.7241 - val_loss: 0.7773 - val_accuracy: 0.7037\n",
            "Epoch 9/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.7181 - accuracy: 0.7350 - val_loss: 0.6203 - val_accuracy: 0.7716\n",
            "Epoch 10/15\n",
            "22/22 [==============================] - 71s 3s/step - loss: 0.6603 - accuracy: 0.7528 - val_loss: 0.6906 - val_accuracy: 0.7452\n",
            "Epoch 11/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.6256 - accuracy: 0.7758 - val_loss: 0.7464 - val_accuracy: 0.7253\n",
            "Epoch 12/15\n",
            "22/22 [==============================] - 71s 3s/step - loss: 0.5942 - accuracy: 0.7772 - val_loss: 0.5535 - val_accuracy: 0.8050\n",
            "Epoch 13/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.5693 - accuracy: 0.7957 - val_loss: 0.5050 - val_accuracy: 0.8175\n",
            "Epoch 14/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.5345 - accuracy: 0.8057 - val_loss: 0.5431 - val_accuracy: 0.8059\n",
            "Epoch 15/15\n",
            "22/22 [==============================] - 70s 3s/step - loss: 0.5097 - accuracy: 0.8131 - val_loss: 0.7343 - val_accuracy: 0.7480\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb99243cd90>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(vtrain,steps_per_epoch=len(vtrain),epochs=15,validation_data=vtest,validation_steps=len(vtest))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNg-GhHVdcHF"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf-WIr1yYrkT"
      },
      "outputs": [],
      "source": [
        "model.save('flowers.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kps61o3ogloY"
      },
      "source": [
        "# Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vXzTadi5ioP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI6RPzAWd_2B"
      },
      "source": [
        "## Test-1 (daisy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MQLllcr4gvdt",
        "outputId": "3b9ba79d-b066-4a3c-efd5-7fc3a647c697"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'daisy'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/daisy/10993818044_4c19b86c82.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvrW-RF5eHXl"
      },
      "source": [
        "## Test-2 (dandelion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Q4vExyy-4g_w",
        "outputId": "ef832d5d-5f1d-4773-bd15-caadb1acab75"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dandelion'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/dandelion/1297972485_33266a18d9.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYSd7ckpeMfj"
      },
      "source": [
        "## Test-3 (rose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K3dk8vORx3mx",
        "outputId": "a880f395-12bb-47ba-87ec-13206740fa79"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rose'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/rose/7456887736_54e4ebac03_n.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z-jmyH7eRHe"
      },
      "source": [
        "## Test-4 (sunflower)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "48WPc6OczA6K",
        "outputId": "eb014747-e906-4c0e-a111-05dae6828252"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sunflower'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/sunflower/7012364067_5ffc7654c9_m.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEgCWdo1eXPO"
      },
      "source": [
        "## Test-5 (tulip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VF4Wx20J0YX5",
        "outputId": "d0d5989c-74aa-49fa-8f69-230db7cc53a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tulip'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = image.load_img('/content/drive/MyDrive/flowers/Testing/tulip/8892851067_79242a7362_n.jpg',target_size=(76,76))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "prediction = np.argmax(model.predict(x))\n",
        "op = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[prediction]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
